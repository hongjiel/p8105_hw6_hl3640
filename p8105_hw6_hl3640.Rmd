---
title: "Homework 6"
author: "Hongjie Liu"
output: github_document
---


Load necessary packages for homework 6.

```{r loadpackages, message = FALSE}
library(tidyverse)
library(modelr)
```


## Problem 1

Load the dataset.

```{r p1_load, message = FALSE}
weather_df =
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"),
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>% 
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>% 
  select(name, id, everything())
```

We use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of $\hat{r} ^ 2$ and $\log (\beta_0 \cdot \beta_1)$. Since we are only interested in `tmin` and `tmax`, we drop all other variables in the dataset.

```{r p1_bootstrap, warning = FALSE}
weather_df = select(weather_df, tmin, tmax)

set.seed(3640)

boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

boot_straps =
  tibble(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

bootstrap_results =
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x)),
    glance = map(models, broom::glance),
    tidy = map(models, broom::tidy)
  ) %>% 
  select(-strap_sample, -models) %>% 
  unnest(glance, tidy) %>% 
  group_by(strap_number) %>% 
  summarize(
    adj_r_squared = min(adj.r.squared),
    log_estimate = log(prod(estimate))
  )

bootstrap_results
```

We plot the distribution of the estimates.

```{r p1_plot1}
bootstrap_results %>% 
  ggplot(aes(x = adj_r_squared)) +
  geom_density() +
  labs(
    title = "Distribution of the estimates of Adjusted R-squared",
    x = "Estimates",
    y = "Density"
  )

bootstrap_results %>% 
  ggplot(aes(x = log_estimate)) +
  geom_density() +
  labs(
    title = "Distribution of the estimates of log(beta_0*beta_1)",
    x = "Estimates",
    y = "Density"
  )
```

We find that both estimates are roughly normally distributed.

We identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for $\hat{r} ^ 2$ and $\log (\beta_0 \cdot \beta_1)$.

```{r p1_ci}
bootstrap_results %>% 
  select(adj_r_squared) %>% 
  summarize(
    lower_bound = quantile(adj_r_squared, .025),
    upper_bound = quantile(adj_r_squared, .975)
  ) %>% 
  knitr::kable(
    caption = "Adjusted R-squared",
    col.names = c("Lower Bound of 95% CI", "Upper Bound of 95% CI"),
    digits = 3
  )

bootstrap_results %>% 
  select(log_estimate) %>% 
  summarize(
    lower_bound = quantile(log_estimate, .025),
    upper_bound = quantile(log_estimate, .975)
  ) %>% 
  knitr::kable(
    caption = "Natural Log of beta_0*beta_1",
    col.names = c("Lower Bound of 95% CI", "Upper Bound of 95% CI"),
    digits = 3
  )
```


## Problem 2

Load the dataset. We create a `city_state` variable and a binary variable indicating whether the homicide is solved. We omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race. We also omit Tulsa, AL – this is a data entry mistake. We limit our analysis those for whom `victim_race` is `white` or `black`.

```{r p2_readtidy, message = FALSE}
homicide_df =
  read_csv("./data/homicide-data.csv") %>% 
  unite(city_state, city:state, sep = ", ") %>% 
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")),
    victim_race %in% c("White", "Black")
  ) %>% 
  mutate(
    solved = ifelse(disposition %in% c("Closed without arrest", "Open/No arrest"), FALSE, TRUE),
    victim_age = as.numeric(victim_age),
    victim_sex = ifelse(victim_sex == "Unknown", NA, victim_sex),
    victim_sex = as.factor(victim_sex),
    victim_race = as.factor(victim_race)
  )
```

For the city of Baltimore, MD, we use the `glm` function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors. We save the output of `glm` as an R object; apply the `broom::tidy` to this object; and obtain the estimate and 95% confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed.

```{r p2_regression}
baltimore_fit =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())

baltimore_fit %>% 
  broom::tidy() %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(
    adjusted_OR_estimate = exp(estimate),
    adjusted_OR_lower = exp(estimate + qnorm(.025) * std.error),
    adjusted_OR_upper = exp(estimate + qnorm(.975) * std.error)
  ) %>% 
  select(adjusted_OR_estimate, adjusted_OR_lower, adjusted_OR_upper) %>% 
  knitr::kable(
    col.names = c("Estimate", "Lower bound of the 95% CI", "Upper bound of the 95% CI"),
    digits = 3
  )
```

Now we run `glm` for each of the cities in our dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. We create a dataframe with estimated ORs and CIs for each city.

```{r p2_regression_all}
adjusted_OR_df =
  homicide_df %>% 
  nest(df = -city_state) %>% 
  mutate(
    models = map(.x = df, ~glm(solved ~ victim_age + victim_sex + victim_race, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(-df, -models) %>% 
  unnest(results) %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(
    adjusted_OR_estimate = exp(estimate),
    adjusted_OR_lower = exp(estimate + qnorm(.025) * std.error),
    adjusted_OR_upper = exp(estimate + qnorm(.975) * std.error)
  ) %>% 
  select(city_state, adjusted_OR_estimate, adjusted_OR_lower, adjusted_OR_upper)

adjusted_OR_df
```

We create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR.

```{r p2_plot, fig.height = 7.5}
adjusted_OR_df %>% 
  ggplot(aes(x = adjusted_OR_estimate, y = fct_reorder(city_state, adjusted_OR_estimate))) +
  geom_point() +
  geom_errorbar(aes(xmax = adjusted_OR_upper, xmin = adjusted_OR_lower)) +
  labs(
    title = "Estimates and CIs of the adjusted OR for solving homicides \n comparing male victims to female victims by city",
    x = "Adjusted Odds Ratio",
    y = "City, State"
  )
```

Comment on the plot.


## Problem 3

Load and clean the data for regression analysis. There are no missing data in the dataframe. We find that the values of `pnumlbw` and `pnumsga` are all zeros, so we are not going to use these two variables as predictors in our regression analysis.

```{r p3_loadtidy}
birthweight_df =
  read_csv("./data/birthweight.csv") %>% 
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  ) %>% 
  select(-pnumlbw, -pnumsga)
```

We use criterion-based procedures. We examine all possible models and choose the “best” using the Bayesian Information Criterion (BIC). We choose the model with the smallest BIC value. The predictors of our final model is `babysex`, `bhead`, `blength`, `delwt`, `frace`, `gaweeks`, `mrace`, `ppbmi`, and `smoken`.

```{r p3_regression}
lm_allsub = leaps::regsubsets(bwt ~ ., data = birthweight_df, nvmax = 21)

plot(lm_allsub, scale = "bic")

my_reg = lm(bwt ~ babysex + bhead + blength + delwt + frace + gaweeks + mrace + ppbmi + smoken, data = birthweight_df)
```

We create a plot of model residuals against fitted values.

```{r p3_residuals}
birthweight_df %>% 
  add_predictions(my_reg) %>% 
  add_residuals(my_reg) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = .25) +
  geom_smooth(se = FALSE, color = "red") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Residuals vs Fitted",
    x = "Fitted Values",
    y = "Residuals"
  )
```

Compare my model to two others:

* Model A: using length at birth and gestational age as predictors (main effects only)
* Model B: using head circumference, length, sex, and all interactions (including the three-way interaction) between these

We make this comparison in terms of the cross-validated prediction error.

```{r p3_comparison}
set.seed(3640)

cv_df =
  crossv_mc(birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test  = map(test,  as_tibble)
  ) %>% 
  mutate(
    my_model = map(.x = train, ~lm(bwt ~ babysex + bhead + blength + delwt + frace + gaweeks + mrace + ppbmi + smoken, data = .x)),
    model_a = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_b = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))
  ) %>% 
  mutate(
    rmse_my_model = map2_dbl(.x = my_model, .y = test, ~rmse(model = .x, data = .y)),
    rmse_model_a  = map2_dbl(.x = model_a,  .y = test, ~rmse(model = .x, data = .y)),
    rmse_model_b  = map2_dbl(.x = model_b,  .y = test, ~rmse(model = .x, data = .y))
  )

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_boxplot()
```
